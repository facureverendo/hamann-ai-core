"""
PRD Builder Module - AI-Powered PRD Generation with Anti-Hallucination Controls
Analyzes input, detects gaps, generates questions, and builds complete PRDs.
"""

import json
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from openai import OpenAI

from prd_template import PRDTemplate, PRD, PRDSection, SectionPriority


@dataclass
class Gap:
    """Represents a missing piece of information in the input."""
    section_key: str
    section_title: str
    priority: SectionPriority
    question: str
    context: str  # Context from original input
    options: Optional[List[str]] = None  # For multiple choice questions


@dataclass
class AnalysisResult:
    """Result of analyzing the input context."""
    product_name: str
    extracted_info: Dict[str, str]  # section_key -> extracted content
    confidence_scores: Dict[str, float]  # section_key -> confidence (0-1)
    explicit_features: List[str]  # Features explicitly mentioned
    inferred_features: List[str]  # Features logically inferred
    gaps: List[Gap]  # Missing information


ANALYSIS_PROMPT = """You are a STRICT information extraction system. Your ONLY job is to COPY information from the source document.

{language_instruction}

ğŸš¨ CRITICAL ANTI-HALLUCINATION RULES ğŸš¨

**ABSOLUTE PROHIBITIONS:**
1. âŒ DO NOT invent ANY features, screens, buttons, or functionality
2. âŒ DO NOT invent API endpoints, feature flags, or technical details
3. âŒ DO NOT invent user personas, roles, or responsibilities
4. âŒ DO NOT invent user flows, states, or interactions
5. âŒ DO NOT add examples, assumptions, or "logical" extensions
6. âŒ DO NOT create generic content to "fill gaps"
7. âŒ DO NOT modify, simplify, or reinterpret what you read

**WHAT YOU MUST DO:**
1. âœ… COPY EXACTLY what is written in the source document
2. âœ… Use LITERAL text from the document (copy-paste mode)
3. âœ… If a detail is mentioned, extract it VERBATIM
4. âœ… If information is missing, mark it as "missing_sections"
5. âœ… Preserve ALL specific details: names, numbers, exact wording
6. âœ… Keep technical terms, feature names, and specifications EXACTLY as written

**EXTRACTION MODE:**
- **Literal copying**: If document says "MÃ³nica is a non-technical admin", write EXACTLY that
- **Preserve specifics**: If document mentions "Feature #41187", keep that exact number
- **No interpretation**: If document says "cluster requests", don't explain HOW - just note it exists
- **No expansion**: If document lists 3 personas, extract ONLY those 3 - don't add a 4th

**EXAMPLES OF VIOLATIONS (DO NOT DO THIS):**

âŒ BAD - Inventing:
- Document mentions "knowledge snippets" â†’ You add "manual snippet generator button"
- Document has "MÃ³nica: Admin" â†’ You add "MÃ³nica analyzes financial reports"
- Document mentions "integration" â†’ You invent "API /api/integration endpoint"

âœ… GOOD - Extracting:
- Document: "MÃ³nica is a non-technical administrator" â†’ Extract: "MÃ³nica is a non-technical administrator"
- Document: "Feature integrates with Solution Recommendation" â†’ Extract: "Integrates with Solution Recommendation"
- Document: "Generates knowledge snippets from requests" â†’ Extract: "Generates knowledge snippets from requests"

**CONFIDENCE SCORING:**
- 1.0 = Information is explicitly stated with details
- 0.8 = Information is clearly mentioned but brief
- 0.5 = Information is implied or partial
- 0.0 = Information is NOT in the document (mark as missing)

**Secciones a analizar:**
{sections_info}

**Formato de salida (JSON):**
{{
  "product_name": "EXACT name from document (or 'Unknown' if not stated)",
  "extracted_info": {{
    "section_key": "LITERAL text copied from document - NO interpretation, NO expansion, NO invention",
    ...
  }},
  "confidence_scores": {{
    "section_key": 0.0-1.0,  // How explicitly is this stated in the document?
    ...
  }},
  "explicit_features": [
    "EXACT feature names/descriptions from document - COPY-PASTE only"
  ],
  "inferred_features": [
    "Features that are CLEARLY implied by explicit statements (use VERY sparingly)"
  ],
  "missing_sections": [
    {{
      "section_key": "section_key",
      "reason": "Brief explanation of why this section is missing or what related information exists"
    }}
  ]
}}

**FINAL CHECK BEFORE RESPONDING:**
- Did I invent ANY feature not in the document? â†’ If YES, REMOVE IT
- Did I add ANY persona details not stated? â†’ If YES, REMOVE IT
- Did I create ANY technical specs not mentioned? â†’ If YES, REMOVE IT
- Did I expand ANY brief mentions into full descriptions? â†’ If YES, REVERT TO BRIEF
- Is EVERY piece of information traceable to the source? â†’ If NO, REMOVE IT

Extract information in LITERAL COPY MODE. When in doubt, mark as missing."""


QUESTION_GENERATION_PROMPT = """Eres un Product Manager experto generando preguntas para completar un PRD.

Tienes informaciÃ³n parcial sobre un producto. Tu trabajo es generar preguntas especÃ­ficas y Ãºtiles para llenar los gaps.

**Reglas:**
1. Haz preguntas especÃ­ficas, no genÃ©ricas
2. Proporciona contexto de lo que YA sabes
3. Ofrece opciones mÃºltiples cuando sea apropiado
4. Prioriza preguntas crÃ­ticas primero
5. MÃ¡ximo {max_questions} preguntas

**InformaciÃ³n que ya tienes:**
{known_info}

**Secciones faltantes (prioridad crÃ­tica):**
{critical_gaps}

**Secciones faltantes (prioridad importante):**
{important_gaps}

**Formato de salida (JSON):**
{{
  "questions": [
    {{
      "section_key": "clave de la secciÃ³n",
      "question": "Pregunta especÃ­fica y clara",
      "context": "Por quÃ© necesito esta informaciÃ³n",
      "options": ["OpciÃ³n 1", "OpciÃ³n 2", "Otro"]  // opcional, para multiple choice
    }}
  ]
}}

Genera preguntas inteligentes y especÃ­ficas."""


def analyze_input(context: str, client: OpenAI, language_code: str = "es") -> AnalysisResult:
    """
    Analyze input context and extract information without hallucinating.
    
    Args:
        context: Raw input from user
        client: OpenAI client
        language_code: Language code for output (en, es, pt, fr, de)
        
    Returns:
        AnalysisResult with extracted info and identified gaps
    """
    # Prepare sections info for the prompt
    sections_info = ""
    for section in PRDTemplate.SECTIONS:
        sections_info += f"- **{section.key}** ({section.priority.value}): {section.description}\n"
    
    # Get language instruction
    from language_detector import get_language_instruction
    language_instruction = get_language_instruction(language_code)
    
    prompt = ANALYSIS_PROMPT.format(
        sections_info=sections_info,
        language_instruction=language_instruction
    )
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"Extract information in LITERAL COPY MODE from this context:\n\n{context}"}
            ],
            response_format={"type": "json_object"},
            temperature=0.05,  # ULTRA-low temperature for pure extraction
            max_tokens=4000  # Increased for detailed documents
        )
        
        content = response.choices[0].message.content
        parsed = json.loads(content)
        
        # Extract data
        product_name = parsed.get("product_name", "Producto Sin Nombre")
        extracted_info = parsed.get("extracted_info", {})
        confidence_scores = parsed.get("confidence_scores", {})
        explicit_features = parsed.get("explicit_features", [])
        inferred_features = parsed.get("inferred_features", [])
        missing_sections = parsed.get("missing_sections", [])
        
        # Create gaps for missing sections with contextual information
        gaps = []
        
        # Handle both old format (list of strings) and new format (list of objects)
        missing_sections_list = missing_sections if isinstance(missing_sections, list) else []
        
        for missing_item in missing_sections_list:
            # Support both formats: string (section_key) or dict (section_key + reason)
            if isinstance(missing_item, dict):
                section_key = missing_item.get("section_key")
                ai_reason = missing_item.get("reason", "")
            else:
                section_key = missing_item
                ai_reason = ""
            
            section = PRDTemplate.get_section(section_key)
            if section:
                # Build context explaining what information exists and why this section is needed
                context_parts = []
                
                # Add AI-generated reason if available
                if ai_reason:
                    context_parts.append(f"RazÃ³n: {ai_reason}")
                
                # Add product name context
                if product_name and product_name != "Producto Sin Nombre":
                    if not ai_reason:
                        context_parts.append(f"Producto: {product_name}")
                
                # Add related extracted information that might be relevant
                related_sections = []
                if section_key == "ux_flows" and "functional_requirements" in extracted_info:
                    related_sections.append("functional_requirements")
                elif section_key == "acceptance_criteria" and "functional_requirements" in extracted_info:
                    related_sections.append("functional_requirements")
                elif section_key == "risks_challenges" and "solution_overview" in extracted_info:
                    related_sections.append("solution_overview")
                elif section_key == "kpis_metrics" and "solution_overview" in extracted_info:
                    related_sections.append("solution_overview")
                elif section_key == "technical_requirements" and "functional_requirements" in extracted_info:
                    related_sections.append("functional_requirements")
                
                if related_sections:
                    context_parts.append("\nInformaciÃ³n relacionada disponible:")
                    for rel_key in related_sections:
                        rel_section = PRDTemplate.get_section(rel_key)
                        if rel_section and rel_key in extracted_info:
                            content_preview = extracted_info[rel_key][:150] + "..." if len(extracted_info[rel_key]) > 150 else extracted_info[rel_key]
                            context_parts.append(f"- {rel_section.title}: {content_preview}")
                
                # Add explicit features context if available
                if explicit_features:
                    context_parts.append(f"\nFeatures identificadas: {', '.join(explicit_features[:3])}")
                    if len(explicit_features) > 3:
                        context_parts.append(f"(y {len(explicit_features) - 3} mÃ¡s)")
                
                # Build context string
                gap_context = "\n".join(context_parts) if context_parts else f"Esta secciÃ³n no fue encontrada en el documento analizado. Es necesaria para completar el PRD del producto '{product_name}'."
                
                # Create a gap with contextual information
                gaps.append(Gap(
                    section_key=section.key,
                    section_title=section.title,
                    priority=section.priority,
                    question="",  # Will be filled by generate_questions
                    context=gap_context
                ))
        
        return AnalysisResult(
            product_name=product_name,
            extracted_info=extracted_info,
            confidence_scores=confidence_scores,
            explicit_features=explicit_features,
            inferred_features=inferred_features,
            gaps=gaps
        )
        
    except Exception as e:
        raise RuntimeError(f"Error analyzing input: {str(e)}")


def generate_questions(analysis: AnalysisResult, client: OpenAI, max_questions: int = 15, language_code: str = "es") -> List[Gap]:
    """
    Generate targeted questions to fill gaps in the PRD.
    
    Args:
        analysis: Result from analyze_input
        client: OpenAI client
        max_questions: Maximum number of questions to generate
        language_code: Language code for questions (en, es, pt, fr, de)
        
    Returns:
        List of Gaps with specific questions
    """
    # If no gaps, return empty list
    if not analysis.gaps:
        print("   â€¢ No hay gaps detectados")
        return []
    
    # Prepare known info summary
    known_info = f"**Producto:** {analysis.product_name}\n\n"
    if analysis.explicit_features:
        known_info += "**Features explÃ­citas:**\n"
        for feature in analysis.explicit_features:
            known_info += f"- {feature}\n"
        known_info += "\n"
    
    if analysis.extracted_info:
        known_info += "**InformaciÃ³n extraÃ­da:**\n"
        for key, value in analysis.extracted_info.items():
            section = PRDTemplate.get_section(key)
            if section:
                known_info += f"- **{section.title}**: {value[:200]}...\n"
        known_info += "\n"
    
    # Separate gaps by priority
    critical_gaps = [g for g in analysis.gaps if g.priority == SectionPriority.CRITICAL]
    important_gaps = [g for g in analysis.gaps if g.priority == SectionPriority.IMPORTANT]
    
    # If no critical or important gaps, return empty (optional sections don't need questions)
    if not critical_gaps and not important_gaps:
        print("   â€¢ Solo gaps opcionales detectados, no se generan preguntas")
        return []
    
    critical_gaps_str = "\n".join([f"- {g.section_title}" for g in critical_gaps])
    important_gaps_str = "\n".join([f"- {g.section_title}" for g in important_gaps])
    
    # Get language instruction
    from language_detector import get_language_instruction
    language_instruction = get_language_instruction(language_code)
    
    # Add language instruction to prompt
    prompt_with_lang = f"{language_instruction}\n\n{QUESTION_GENERATION_PROMPT}"
    
    prompt = prompt_with_lang.format(
        max_questions=max_questions,
        known_info=known_info,
        critical_gaps=critical_gaps_str if critical_gaps_str else "Ninguna",
        important_gaps=important_gaps_str if important_gaps_str else "Ninguna"
    )
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": "Genera preguntas especÃ­ficas para completar el PRD."}
            ],
            response_format={"type": "json_object"},
            temperature=0.3,
            max_tokens=2000
        )
        
        content = response.choices[0].message.content
        parsed = json.loads(content)
        
        questions_data = parsed.get("questions", [])
        
        # Create Gap objects with questions
        gaps_with_questions = []
        for q_data in questions_data[:max_questions]:
            section_key = q_data.get("section_key")
            section = PRDTemplate.get_section(section_key)
            
            if section:
                gap = Gap(
                    section_key=section.key,
                    section_title=section.title,
                    priority=section.priority,
                    question=q_data.get("question", ""),
                    context=q_data.get("context", ""),
                    options=q_data.get("options")
                )
                gaps_with_questions.append(gap)
        
        return gaps_with_questions
        
    except Exception as e:
        raise RuntimeError(f"Error generating questions: {str(e)}")


def build_prd(
    analysis: AnalysisResult,
    user_answers: Dict[str, str],
    client: OpenAI,
    language_code: str = "es"
) -> PRD:
    """
    Build complete PRD from analysis and user answers.
    
    Args:
        analysis: Initial analysis result
        user_answers: User's answers to questions (section_key -> answer)
        client: OpenAI client
        language_code: Language code for PRD (en, es, pt, fr, de)
        
    Returns:
        Complete PRD object
    """
    # Combine extracted info with user answers
    all_content = {**analysis.extracted_info, **user_answers}
    
    # Build PRD sections using AI to format nicely
    prd_sections = {}
    
    for section in PRDTemplate.SECTIONS:
        content = all_content.get(section.key, "")
        
        # Skip sections that are explicitly marked as missing or empty
        if not content or content.strip() == "" or content.strip().lower() == "missing_sections":
            continue
        
        # Use AI to format the content professionally
        formatted_content = _format_section_content(
            section=section,
            raw_content=content,
            product_name=analysis.product_name,
            client=client,
            language_code=language_code
        )
        prd_sections[section.key] = formatted_content
    
    # Create metadata
    from datetime import datetime
    metadata = {
        "Generated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "Explicit Features": ", ".join(analysis.explicit_features[:5]),
        "Confidence": f"{sum(analysis.confidence_scores.values()) / len(analysis.confidence_scores):.0%}" if analysis.confidence_scores else "N/A"
    }
    
    return PRD(
        product_name=analysis.product_name,
        sections=prd_sections,
        metadata=metadata
    )


def _format_section_content(
    section: PRDSection,
    raw_content: str,
    product_name: str,
    client: OpenAI,
    language_code: str = "es"
) -> str:
    """
    Format section content with STRICT preservation of source material.
    
    Args:
        section: PRD section
        raw_content: Raw content from extraction or user answer
        product_name: Name of the product
        client: OpenAI client
        language_code: Language code for formatting (en, es, pt, fr, de)
        
    Returns:
        Professionally formatted content (structure only, NO new content)
    """
    # Get language instruction
    from language_detector import get_language_instruction
    language_instruction = get_language_instruction(language_code)
    
    # ULTRA-STRICT formatting prompt
    prompt = f"""{language_instruction}

ğŸš¨ CRITICAL: You are a FORMATTING ASSISTANT, NOT a content creator ğŸš¨

Your ONLY job is to add Markdown structure to existing content. You MUST NOT add ANY new information.

**Product:** {product_name}
**Section:** {section.title}
**Section Purpose:** {section.description}

**Raw Content (to be formatted ONLY):**
{raw_content}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ›‘ ABSOLUTE PROHIBITIONS - DO NOT VIOLATE THESE ğŸ›‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ DO NOT add features, screens, buttons, or functionality not in raw content
âŒ DO NOT add persona details, responsibilities, or characteristics not stated
âŒ DO NOT add API endpoints, technical specs, or implementation details not mentioned
âŒ DO NOT add user flows, states, or interactions not described
âŒ DO NOT add examples, use cases, or scenarios not provided
âŒ DO NOT add metrics, KPIs, or measurements not specified
âŒ DO NOT expand brief mentions into detailed descriptions
âŒ DO NOT interpret, assume, or infer anything beyond what's written
âŒ DO NOT add "professional" filler content
âŒ DO NOT create subsections for content that doesn't exist

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… WHAT YOU MUST DO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **PRESERVE EXACTLY**: Every word, name, number, and detail from raw content
2. **ADD ONLY STRUCTURE**: Headers (###, ####), lists (-, 1.), tables, bold/italic
3. **KEEP VERBATIM**: Technical terms, feature names, persona names, specifications
4. **NO EXPANSION**: If raw content is brief, keep it brief
5. **NO INVENTION**: If a detail isn't mentioned, don't add it

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ FORMATTING GUIDELINES (Structure Only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Allowed Formatting:**
- Add headers (###, ####) to organize content
- Convert to bullet lists (-) or numbered lists (1.)
- Add tables for structured data
- Add **bold** for emphasis on existing key terms
- Add code blocks (\`\`\`) for technical specs that exist in raw content
- Add line breaks for readability

**Forbidden Actions:**
- Adding new sentences or paragraphs
- Expanding abbreviations or brief mentions
- Creating examples not in raw content
- Adding context or explanations
- Filling in "obvious" gaps
- Making content more "complete"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ EXAMPLES OF VIOLATIONS (DO NOT DO THIS)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ **BAD - Adding content:**

Raw: "MÃ³nica is an administrator"
Bad output: "MÃ³nica is a non-technical administrator responsible for user management, system configuration, and reporting. She needs intuitive interfaces..."

âœ… **GOOD - Formatting only:**

Raw: "MÃ³nica is an administrator"
Good output: "**MÃ³nica**: Administrator"

---

âŒ **BAD - Inventing details:**

Raw: "Feature generates knowledge snippets"
Bad output: "### Knowledge Snippet Generation\n- Manual generation via 'Generate Snippet' button\n- Automatic generation from request analysis\n- Classification as novel/complementary/redundant"

âœ… **GOOD - Preserving exactly:**

Raw: "Feature generates knowledge snippets"
Good output: "### Knowledge Snippet Generation\nFeature generates knowledge snippets"

---

âŒ **BAD - Expanding personas:**

Raw: "Jorge: End user"
Bad output: "**Jorge** - End User\n- Analyzes financial reports\n- Reviews dashboards\n- Makes data-driven decisions"

âœ… **GOOD - Literal preservation:**

Raw: "Jorge: End user"
Good output: "**Jorge**: End user"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ YOUR TASK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Read the raw content carefully
2. Identify natural groupings or lists
3. Add Markdown structure (headers, lists, tables)
4. Preserve EVERY detail exactly as written
5. Do NOT add ANY new information

**Output Requirements:**
- Return ONLY the formatted content
- NO explanations, NO "Here is...", NO meta-commentary
- Start directly with the formatted content
- If raw content is empty/minimal, output should be empty/minimal

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ“ FINAL CHECKLIST BEFORE RESPONDING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Before you output, verify:

â–¡ Did I add ANY feature not in raw content? â†’ If YES, REMOVE IT
â–¡ Did I add ANY persona detail not stated? â†’ If YES, REMOVE IT  
â–¡ Did I add ANY technical spec not mentioned? â†’ If YES, REMOVE IT
â–¡ Did I expand ANY brief mention? â†’ If YES, REVERT TO BRIEF
â–¡ Did I add ANY example not provided? â†’ If YES, REMOVE IT
â–¡ Is EVERY sentence traceable to raw content? â†’ If NO, REMOVE IT
â–¡ Did I only add formatting (headers, lists, bold)? â†’ Must be YES

**If you added ANYTHING beyond formatting, you FAILED. Remove it.**

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Now format the raw content with ZERO additions. Structure only."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a strict formatting assistant. You add Markdown structure to content but NEVER add new information. You preserve source material exactly as written."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # Very low for literal preservation
            max_tokens=2500
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        # Fallback: return raw content if formatting fails
        print(f"âš ï¸  Warning: Failed to format section {section.key}: {str(e)}")
        return raw_content
